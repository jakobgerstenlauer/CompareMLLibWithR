//This code is based on a code snippet from: 
//https://spark.apache.org/docs/1.1.0/mllib-linear-methods.html#linear-least-squares-lasso-and-ridge-regression
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.evaluation.RegressionMetrics
import org.apache.spark.mllib.regression.LinearRegressionModel
import org.apache.spark.mllib.regression.LassoWithSGD
import org.apache.spark.ml.tuning.CrossValidator

//Check if a input line represents the header of the input file.
def isHeader(line: String) = line.contains("output");
 
var fileName = "foo.txt"
var path = "file:///home/.../data/"
println("Reading data from file: " + fileName)
val data = sc.textFile(path + fileName).filter(!isHeader(_))

val parsedData = data.map { line =>
  val parts = line.split(';')
  LabeledPoint(parts(0).toDouble, Vectors.dense(parts(1).split(' ').map(_.toDouble)))
}.cache()

// Building the model
val numIterations = 10000
val stepSize = 0.01
val lambda = 1
 
val model = LassoWithSGD.train(parsedData, numIterations, stepSize, lambda)

// Evaluate model on training examples and compute training error
val valuesAndPreds = parsedData.map { point =>
  val prediction = model.predict(point.features)
  (point.label, prediction)
}

val metrics = new RegressionMetrics(valuesAndPreds)

// We use a ParamGridBuilder to construct a grid of parameters to search over.
// With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,
// this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.
val paramGrid = new ParamGridBuilder().addGrid(model.regParam, (0.0 to 1.0 by 0.01).toArray).build()
  
val cv = new CrossValidator()
  .setEstimator(model)
  .setEvaluator(metrics)
  .setEstimatorParamMaps(paramGrid)
  .setNumFolds(5)
  
// Run cross-validation, and choose the best set of parameters.
val cvModel = cv.fit(training)
